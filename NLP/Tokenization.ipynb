{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "### Tokenization is the process to split the paragraphs into sentences or words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello my name is kuchhadiya punja. i study at ld college of engineering. i am currently enrolled in artificial intelligence and machine learning course of udemy. i am currently learning NLP! in NLP i am currently learning tokenization using NLTK.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is kuchhadiya punja.\n",
      "i study at ld college of engineering.\n",
      "i am currently enrolled in artificial intelligence and machine learning course of udemy.\n",
      "i am currently learning NLP!\n",
      "in NLP i am currently learning tokenization using NLTK.\n"
     ]
    }
   ],
   "source": [
    "document = sent_tokenize(corpus, language='english')\n",
    "for i in document:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'kuchhadiya',\n",
       " 'punja',\n",
       " '.',\n",
       " 'i',\n",
       " 'study',\n",
       " 'at',\n",
       " 'ld',\n",
       " 'college',\n",
       " 'of',\n",
       " 'engineering',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'course',\n",
       " 'of',\n",
       " 'udemy',\n",
       " '.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '!',\n",
       " 'in',\n",
       " 'NLP',\n",
       " 'i',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'learning',\n",
       " 'tokenization',\n",
       " 'using',\n",
       " 'NLTK',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "### Stemming is the process of removing the prefix and suffix of the words\n",
    "#### for example moves, moving, moved are basically 'move'. so it converts all of this to their stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"running\", \"jumps\", \"easily\", \"faster\", \"happily\", \"studies\", \"flies\",  \n",
    "    \"driving\", \"eaten\", \"creating\", \"better\", \"stronger\", \"worse\",  \n",
    "    \"fishing\", \"thoughtful\", \"walking\", \"unhappiness\", \"nationality\",  \n",
    "    \"singing\", \"organization\", \"arguing\", \"simplified\", \"playing\",  \n",
    "    \"working\", \"swimming\", \"quickly\", \"married\", \"loving\", \"caring\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running-------->run\n",
      "jumps-------->jump\n",
      "easily-------->easili\n",
      "faster-------->faster\n",
      "happily-------->happili\n",
      "studies-------->studi\n",
      "flies-------->fli\n",
      "driving-------->drive\n",
      "eaten-------->eaten\n",
      "creating-------->creat\n",
      "better-------->better\n",
      "stronger-------->stronger\n",
      "worse-------->wors\n",
      "fishing-------->fish\n",
      "thoughtful-------->thought\n",
      "walking-------->walk\n",
      "unhappiness-------->unhappi\n",
      "nationality-------->nation\n",
      "singing-------->sing\n",
      "organization-------->organ\n",
      "arguing-------->argu\n",
      "simplified-------->simplifi\n",
      "playing-------->play\n",
      "working-------->work\n",
      "swimming-------->swim\n",
      "quickly-------->quickli\n",
      "married-------->marri\n",
      "loving-------->love\n",
      "caring-------->care\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in words:\n",
    "    print((i)+\"-------->\"+ps.stem(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "ss = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goe\n",
      "fairli\n",
      "goe\n",
      "fair\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('goes'))\n",
    "print(ps.stem(\"fairly\"))\n",
    "print(ss.stem(\"goes\"))\n",
    "print(ss.stem(\"fairly\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization:\n",
    "### Lemmatization is similar to stemming where the output is called 'lemma' which is the root word of the input word\n",
    "#### as seen above stemming is great but it fails in some cases like goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lmtz = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running-------->run\n",
      "jumps-------->jump\n",
      "easily-------->easily\n",
      "faster-------->faster\n",
      "happily-------->happily\n",
      "studies-------->study\n",
      "flies-------->fly\n",
      "driving-------->drive\n",
      "eaten-------->eat\n",
      "creating-------->create\n",
      "better-------->better\n",
      "stronger-------->stronger\n",
      "worse-------->worse\n",
      "fishing-------->fish\n",
      "thoughtful-------->thoughtful\n",
      "walking-------->walk\n",
      "unhappiness-------->unhappiness\n",
      "nationality-------->nationality\n",
      "singing-------->sing\n",
      "organization-------->organization\n",
      "arguing-------->argue\n",
      "simplified-------->simplify\n",
      "playing-------->play\n",
      "working-------->work\n",
      "swimming-------->swim\n",
      "quickly-------->quickly\n",
      "married-------->marry\n",
      "loving-------->love\n",
      "caring-------->care\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in words:\n",
    "    print((i)+\"-------->\"+lmtz.lemmatize(i,pos='v'))\n",
    "\n",
    "    ## much better result compared to stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmtz.lemmatize('goes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming is fast but sometimes it dont give good results\n",
    "## Lemmatizer is slow but better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords:\n",
    "###  all the extra words are called stopwords.\n",
    "#### Eg:The,Their etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"In the year 1960, APJ Abdul Kalam’s graduation took place from Madras Institute of Technology. The association of Kalam took place with the Defence Research & Development Service (DRDS). Furthermore, he joined as a scientist at the Aeronautical Development Establishment of the Defence Research and Development Organisation. These were the beginning achievements of his prestigious career as a scientist.Big achievement for Kalam came when he was the project director at ISRO of India‘s first-ever Satellite Launch Vehicle (SLV- III). This satellite was responsible for the deployment of the Rohini satellite in 1980. Moreover, Kalam was highly influential in the development of Polar Satellite Launch Vehicle (PSLV) and SLV projects.Both projects were successful. Bringing enhancement in the reputation of Kalam. Furthermore, the development of ballistic missiles was possible because of the efforts of this man. Most noteworthy, Kalam earned the esteemed title of “The missile Man of India”. The Government of India became aware of the brilliance of this man and made him the Chief Executive of the Integrated Guided Missiles Development Program (IGMDP). Furthermore, this program was responsible for the research and development of Missiles. The achievements of this distinguished man didn't stop there.More success was to come in the form of Agni and Prithvi missiles. Once again, Kalam was influential in the developments of these missiles. It was during his tenure in IGMDP that Kalam played an instrumental role in the developments of missiles like Agni and Prithvi. Moreover, Kamal was a key figure in the Pokhran II nuclear test.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the year 1960, APJ Abdul Kalam’s graduation took place from Madras Institute of Technology. The association of Kalam took place with the Defence Research & Development Service (DRDS). Furthermore, he joined as a scientist at the Aeronautical Development Establishment of the Defence Research and Development Organisation. These were the beginning achievements of his prestigious career as a scientist.Big achievement for Kalam came when he was the project director at ISRO of India‘s first-ever Satellite Launch Vehicle (SLV- III). This satellite was responsible for the deployment of the Rohini satellite in 1980. Moreover, Kalam was highly influential in the development of Polar Satellite Launch Vehicle (PSLV) and SLV projects.Both projects were successful. Bringing enhancement in the reputation of Kalam. Furthermore, the development of ballistic missiles was possible because of the efforts of this man. Most noteworthy, Kalam earned the esteemed title of “The missile Man of India”. The Government of India became aware of the brilliance of this man and made him the Chief Executive of the Integrated Guided Missiles Development Program (IGMDP). Furthermore, this program was responsible for the research and development of Missiles. The achievements of this distinguished man didn't stop there.More success was to come in the form of Agni and Prithvi missiles. Once again, Kalam was influential in the developments of these missiles. It was during his tenure in IGMDP that Kalam played an instrumental role in the developments of missiles like Agni and Prithvi. Moreover, Kamal was a key figure in the Pokhran II nuclear test.\n"
     ]
    }
   ],
   "source": [
    "print(para)\n",
    "\n",
    "\n",
    "\n",
    "## for removing all punctuation\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# tokens = tokenizer.tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_stem= [ss.stem(word) for word in para if word not in set(stopwords.words())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_lmtz= [lmtz.lemmatize(word,pos='v') for word in para if word not in set(stopwords.words())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"in year 1960 , apj abdul kalam ’ graduat place madra institut technolog . the associ kalam place defenc research & develop servic ( drds ) . furthermor , join scientist aeronaut develop establish defenc research develop organis . these begin achiev prestigi career scientist.big achiev kalam project director isro india ‘ first-ev satellit launch vehicl ( slv- iii ) . this satellit respons deploy rohini satellit 1980 . moreov , kalam high influenti develop polar satellit launch vehicl ( pslv ) slv projects.both project success . bring enhanc reput kalam . furthermor , develop ballist missil possibl effort . most noteworthi , kalam earn esteem titl “ the missil man india ” . the govern india awar brillianc made chief execut integr guid missil develop program ( igmdp ) . furthermor , program respons research develop missil . the achiev distinguish n't stop there.mor success form agni prithvi missil . onc , kalam influenti develop missil . it tenur igmdp kalam play instrument role develop missil agni prithvi . moreov , kamal key figur pokhran ii nuclear test .\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(para_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_lmtzz = \" \".join(para_lmtz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lwr_lmtz = []\n",
    "for word in para_lmtzz:\n",
    "    lwr_lmtz.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'year', '1960', ',', 'apj', 'abdul', 'kalam', '’', 'graduat', 'place', 'madra', 'institut', 'technolog', '.', 'the', 'associ', 'kalam', 'place', 'defenc', 'research', '&', 'develop', 'servic', '(', 'drds', ')', '.', 'furthermor', ',', 'join', 'scientist', 'aeronaut', 'develop', 'establish', 'defenc', 'research', 'develop', 'organis', '.', 'these', 'begin', 'achiev', 'prestigi', 'career', 'scientist.big', 'achiev', 'kalam', 'project', 'director', 'isro', 'india', '‘', 'first-ev', 'satellit', 'launch', 'vehicl', '(', 'slv-', 'iii', ')', '.', 'this', 'satellit', 'respons', 'deploy', 'rohini', 'satellit', '1980', '.', 'moreov', ',', 'kalam', 'high', 'influenti', 'develop', 'polar', 'satellit', 'launch', 'vehicl', '(', 'pslv', ')', 'slv', 'projects.both', 'project', 'success', '.', 'bring', 'enhanc', 'reput', 'kalam', '.', 'furthermor', ',', 'develop', 'ballist', 'missil', 'possibl', 'effort', '.', 'most', 'noteworthi', ',', 'kalam', 'earn', 'esteem', 'titl', '“', 'the', 'missil', 'man', 'india', '”', '.', 'the', 'govern', 'india', 'awar', 'brillianc', 'made', 'chief', 'execut', 'integr', 'guid', 'missil', 'develop', 'program', '(', 'igmdp', ')', '.', 'furthermor', ',', 'program', 'respons', 'research', 'develop', 'missil', '.', 'the', 'achiev', 'distinguish', \"n't\", 'stop', 'there.mor', 'success', 'form', 'agni', 'prithvi', 'missil', '.', 'onc', ',', 'kalam', 'influenti', 'develop', 'missil', '.', 'it', 'tenur', 'igmdp', 'kalam', 'play', 'instrument', 'role', 'develop', 'missil', 'agni', 'prithvi', '.', 'moreov', ',', 'kamal', 'key', 'figur', 'pokhran', 'ii', 'nuclear', 'test', '.']\n",
      "['i', 'n', ' ', 'y', 'e', 'a', 'r', ' ', '1', '9', '6', '0', ' ', ',', ' ', 'a', 'p', 'j', ' ', 'a', 'b', 'd', 'u', 'l', ' ', 'k', 'a', 'l', 'a', 'm', ' ', '’', ' ', 'g', 'r', 'a', 'd', 'u', 'a', 't', 'i', 'o', 'n', ' ', 'p', 'l', 'a', 'c', 'e', ' ', 'm', 'a', 'd', 'r', 'a', 's', ' ', 'i', 'n', 's', 't', 'i', 't', 'u', 't', 'e', ' ', 't', 'e', 'c', 'h', 'n', 'o', 'l', 'o', 'g', 'y', ' ', '.', ' ', 't', 'h', 'e', ' ', 'a', 's', 's', 'o', 'c', 'i', 'a', 't', 'i', 'o', 'n', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'p', 'l', 'a', 'c', 'e', ' ', 'd', 'e', 'f', 'e', 'n', 'c', 'e', ' ', 'r', 'e', 's', 'e', 'a', 'r', 'c', 'h', ' ', '&', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 's', 'e', 'r', 'v', 'i', 'c', 'e', ' ', '(', ' ', 'd', 'r', 'd', 's', ' ', ')', ' ', '.', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', 'm', 'o', 'r', 'e', ' ', ',', ' ', 'j', 'o', 'i', 'n', ' ', 's', 'c', 'i', 'e', 'n', 't', 'i', 's', 't', ' ', 'a', 'e', 'r', 'o', 'n', 'a', 'u', 't', 'i', 'c', 'a', 'l', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'e', 's', 't', 'a', 'b', 'l', 'i', 's', 'h', 'm', 'e', 'n', 't', ' ', 'd', 'e', 'f', 'e', 'n', 'c', 'e', ' ', 'r', 'e', 's', 'e', 'a', 'r', 'c', 'h', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'o', 'r', 'g', 'a', 'n', 'i', 's', 'a', 't', 'i', 'o', 'n', ' ', '.', ' ', 't', 'h', 'e', 's', 'e', ' ', 'b', 'e', 'g', 'i', 'n', ' ', 'a', 'c', 'h', 'i', 'e', 'v', 'e', 'm', 'e', 'n', 't', 's', ' ', 'p', 'r', 'e', 's', 't', 'i', 'g', 'i', 'o', 'u', 's', ' ', 'c', 'a', 'r', 'e', 'e', 'r', ' ', 's', 'c', 'i', 'e', 'n', 't', 'i', 's', 't', '.', 'b', 'i', 'g', ' ', 'a', 'c', 'h', 'i', 'e', 'v', 'e', 'm', 'e', 'n', 't', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'd', 'i', 'r', 'e', 'c', 't', 'o', 'r', ' ', 'i', 's', 'r', 'o', ' ', 'i', 'n', 'd', 'i', 'a', ' ', '‘', ' ', 'f', 'i', 'r', 's', 't', '-', 'e', 'v', 'e', 'r', ' ', 's', 'a', 't', 'e', 'l', 'l', 'i', 't', 'e', ' ', 'l', 'a', 'u', 'n', 'c', 'h', ' ', 'v', 'e', 'h', 'i', 'c', 'l', 'e', ' ', '(', ' ', 's', 'l', 'v', '-', ' ', 'i', 'i', 'i', ' ', ')', ' ', '.', ' ', 't', 'h', 'i', 's', ' ', 's', 'a', 't', 'e', 'l', 'l', 'i', 't', 'e', ' ', 'r', 'e', 's', 'p', 'o', 'n', 's', 'i', 'b', 'l', 'e', ' ', 'd', 'e', 'p', 'l', 'o', 'y', 'm', 'e', 'n', 't', ' ', 'r', 'o', 'h', 'i', 'n', 'i', ' ', 's', 'a', 't', 'e', 'l', 'l', 'i', 't', 'e', ' ', '1', '9', '8', '0', ' ', '.', ' ', 'm', 'o', 'r', 'e', 'o', 'v', 'e', 'r', ' ', ',', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'h', 'i', 'g', 'h', 'l', 'y', ' ', 'i', 'n', 'f', 'l', 'u', 'e', 'n', 't', 'i', 'a', 'l', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'p', 'o', 'l', 'a', 'r', ' ', 's', 'a', 't', 'e', 'l', 'l', 'i', 't', 'e', ' ', 'l', 'a', 'u', 'n', 'c', 'h', ' ', 'v', 'e', 'h', 'i', 'c', 'l', 'e', ' ', '(', ' ', 'p', 's', 'l', 'v', ' ', ')', ' ', 's', 'l', 'v', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', 's', '.', 'b', 'o', 't', 'h', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 's', 'u', 'c', 'c', 'e', 's', 's', 'f', 'u', 'l', ' ', '.', ' ', 'b', 'r', 'i', 'n', 'g', 'i', 'n', 'g', ' ', 'e', 'n', 'h', 'a', 'n', 'c', 'e', 'm', 'e', 'n', 't', ' ', 'r', 'e', 'p', 'u', 't', 'a', 't', 'i', 'o', 'n', ' ', 'k', 'a', 'l', 'a', 'm', ' ', '.', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', 'm', 'o', 'r', 'e', ' ', ',', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'b', 'a', 'l', 'l', 'i', 's', 't', 'i', 'c', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', 'p', 'o', 's', 's', 'i', 'b', 'l', 'e', ' ', 'e', 'f', 'f', 'o', 'r', 't', 's', ' ', '.', ' ', 'm', 'o', 's', 't', ' ', 'n', 'o', 't', 'e', 'w', 'o', 'r', 't', 'h', 'y', ' ', ',', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'e', 'a', 'r', 'n', ' ', 'e', 's', 't', 'e', 'e', 'm', ' ', 't', 'i', 't', 'l', 'e', ' ', '“', ' ', 't', 'h', 'e', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', ' ', 'm', 'a', 'n', ' ', 'i', 'n', 'd', 'i', 'a', ' ', '”', ' ', '.', ' ', 't', 'h', 'e', ' ', 'g', 'o', 'v', 'e', 'r', 'n', 'm', 'e', 'n', 't', ' ', 'i', 'n', 'd', 'i', 'a', ' ', 'a', 'w', 'a', 'r', 'e', ' ', 'b', 'r', 'i', 'l', 'l', 'i', 'a', 'n', 'c', 'e', ' ', 'm', 'a', 'k', 'e', ' ', 'c', 'h', 'i', 'e', 'f', ' ', 'e', 'x', 'e', 'c', 'u', 't', 'i', 'v', 'e', ' ', 'i', 'n', 't', 'e', 'g', 'r', 'a', 't', 'e', 'd', ' ', 'g', 'u', 'i', 'd', 'e', 'd', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', ' ', '(', ' ', 'i', 'g', 'm', 'd', 'p', ' ', ')', ' ', '.', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', 'm', 'o', 'r', 'e', ' ', ',', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', ' ', 'r', 'e', 's', 'p', 'o', 'n', 's', 'i', 'b', 'l', 'e', ' ', 'r', 'e', 's', 'e', 'a', 'r', 'c', 'h', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', '.', ' ', 't', 'h', 'e', ' ', 'a', 'c', 'h', 'i', 'e', 'v', 'e', 'm', 'e', 'n', 't', 's', ' ', 'd', 'i', 's', 't', 'i', 'n', 'g', 'u', 'i', 's', 'h', ' ', 'n', \"'\", 't', ' ', 's', 't', 'o', 'p', ' ', 't', 'h', 'e', 'r', 'e', '.', 'm', 'o', 'r', 'e', ' ', 's', 'u', 'c', 'c', 'e', 's', 's', ' ', 'f', 'o', 'r', 'm', ' ', 'a', 'g', 'n', 'i', ' ', 'p', 'r', 'i', 't', 'h', 'v', 'i', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', '.', ' ', 'o', 'n', 'c', 'e', ' ', ',', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'i', 'n', 'f', 'l', 'u', 'e', 'n', 't', 'i', 'a', 'l', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', 's', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', '.', ' ', 'i', 't', ' ', 't', 'e', 'n', 'u', 'r', 'e', ' ', 'i', 'g', 'm', 'd', 'p', ' ', 'k', 'a', 'l', 'a', 'm', ' ', 'p', 'l', 'a', 'y', ' ', 'i', 'n', 's', 't', 'r', 'u', 'm', 'e', 'n', 't', 'a', 'l', ' ', 'r', 'o', 'l', 'e', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', 's', ' ', 'm', 'i', 's', 's', 'i', 'l', 'e', 's', ' ', 'a', 'g', 'n', 'i', ' ', 'p', 'r', 'i', 't', 'h', 'v', 'i', ' ', '.', ' ', 'm', 'o', 'r', 'e', 'o', 'v', 'e', 'r', ' ', ',', ' ', 'k', 'a', 'm', 'a', 'l', ' ', 'k', 'e', 'y', ' ', 'f', 'i', 'g', 'u', 'r', 'e', ' ', 'p', 'o', 'k', 'h', 'r', 'a', 'n', ' ', 'i', 'i', ' ', 'n', 'u', 'c', 'l', 'e', 'a', 'r', ' ', 't', 'e', 's', 't', ' ', '.']\n"
     ]
    }
   ],
   "source": [
    "print(para_stem)\n",
    "print(lwr_lmtz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
